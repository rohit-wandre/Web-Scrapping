{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b2fc5ad5-d361-4ab5-8041-f928b7b21a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0aece6b6-43da-4e56-91bb-a781dd8bd3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.nykaa.com/search/result/?q=Diapers&root=search&searchType=Misc&suggestionType=category&ssp=2&tst=diapers&searchItem=Diapers&sourcepage=Category%20Page&'\n",
    "\n",
    "# let us initiate our driver firstly\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d28ddf3-f4e9-444a-8499-46043c58c9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: \n",
      "Stacktrace:\n",
      "Backtrace:\n",
      "\tGetHandleVerifier [0x002FA813+48355]\n",
      "\t(No symbol) [0x0028C4B1]\n",
      "\t(No symbol) [0x00195358]\n",
      "\t(No symbol) [0x001C09A5]\n",
      "\t(No symbol) [0x001C0B3B]\n",
      "\t(No symbol) [0x001EE232]\n",
      "\t(No symbol) [0x001DA784]\n",
      "\t(No symbol) [0x001EC922]\n",
      "\t(No symbol) [0x001DA536]\n",
      "\t(No symbol) [0x001B82DC]\n",
      "\t(No symbol) [0x001B93DD]\n",
      "\tGetHandleVerifier [0x0055AABD+2539405]\n",
      "\tGetHandleVerifier [0x0059A78F+2800735]\n",
      "\tGetHandleVerifier [0x0059456C+2775612]\n",
      "\tGetHandleVerifier [0x003851E0+616112]\n",
      "\t(No symbol) [0x00295F8C]\n",
      "\t(No symbol) [0x00292328]\n",
      "\t(No symbol) [0x0029240B]\n",
      "\t(No symbol) [0x00284FF7]\n",
      "\tBaseThreadInitThunk [0x76D57D59+25]\n",
      "\tRtlInitializeExceptionChain [0x7793B79B+107]\n",
      "\tRtlClearBits [0x7793B71F+191]\n",
      "\t(No symbol) [0x00000000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let us create an empty lists to store the data\n",
    "data_dict = {\n",
    "    'Product_Names':[],\n",
    "    'Product_URLs':[],\n",
    "    'Current_Price':[],\n",
    "    'Original_Price':[],\n",
    "    'Discount_Percentage':[],\n",
    "    'Units_Sold':[],\n",
    "    'Reviews':[] ,\n",
    "    'Featured':[],\n",
    "    'Best_Seller':[]\n",
    "}\n",
    "\n",
    "\n",
    "# Lets us define a function to retireve the information we need\n",
    "def get_page_data(driver, data_dict):\n",
    "    #suppose we want to selenium to wait for it to exist on the page.\n",
    "    #Explict waits\n",
    "    try:\n",
    "        element = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CLASS_NAME, 'css-d5z3ro')))\n",
    "        search_results = driver.find_elements(By.CLASS_NAME, 'css-d5z3ro')\n",
    "        \n",
    "        for result in search_results:\n",
    "            product_name = result.find_element(By.CLASS_NAME, 'css-xrzmfa').text\n",
    "            product_url = result.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "            current_price = result.find_element(By.CLASS_NAME, 'css-111z9ua').text\n",
    "            current_price = current_price.replace('₹','')\n",
    "            try:\n",
    "                original_price = result.find_element(By.CLASS_NAME, 'css-17x46n5').text\n",
    "                original_price = original_price.replace('MRP:','')\n",
    "                if original_price.__contains__('₹'):\n",
    "                    original_price = original_price.replace('₹','')\n",
    "            except NoSuchElementException:\n",
    "                original_price = \"N/A\"\n",
    "            try:\n",
    "                discount_percentage = result.find_element(By.CLASS_NAME,'css-cjd9an').text\n",
    "                discount_percentage = discount_percentage.replace(' Off','')\n",
    "            except NoSuchElementException:\n",
    "                discount_percentage = \"N/A\"\n",
    "            try:\n",
    "                units_sold = result.find_element(By.CLASS_NAME,'_1cEkb').text\n",
    "            except NoSuchElementException:\n",
    "                units_sold = \"N/A\"\n",
    "            try:\n",
    "                reviews = result.find_element(By.CLASS_NAME,'css-1qbvrhp').text\n",
    "            except NoSuchElementException:\n",
    "                reviews = \"N/A\"\n",
    "            try:\n",
    "                featured = result.find_element(By.CLASS_NAME,'css-1jnild6').text\n",
    "            except NoSuchElementException:\n",
    "                featured = \"N/A\"\n",
    "            try:\n",
    "                best_seller = result.find_element(By.CLASS_NAME,'css-1bse542').text\n",
    "            except NoSuchElementException:\n",
    "                best_seller = \"N/A\"\n",
    "            \n",
    "         \n",
    "            # Append the empty lists with the data we have\n",
    "            data_dict['Product_Names'].append(product_name)\n",
    "            data_dict['Product_URLs'].append(product_url)\n",
    "            data_dict['Current_Price'].append(current_price)\n",
    "            data_dict['Original_Price'].append(original_price)\n",
    "            data_dict['Discount_Percentage'].append(discount_percentage)\n",
    "            data_dict['Units_Sold'].append(units_sold)\n",
    "            data_dict['Reviews'].append(reviews)\n",
    "            data_dict['Featured'].append(featured)\n",
    "            data_dict['Best_Seller'].append(best_seller)\n",
    "    except NoSuchElementException:\n",
    "        print(\"Some elements not found for this product.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        loadMoreButton = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.XPATH,\"//*[@id='load-more']\")))\n",
    "        # loadMoreButton = driver.find_element(By.XPATH,\"//*[@id='load-more']\")\n",
    "        # time.sleep(30)\n",
    "        # loadMoreButton.click()\n",
    "        webdriver.ActionChains(driver).move_to_element(loadMoreButton).click(loadMoreButton).perform()\n",
    "        time.sleep(30)\n",
    "        no_more_elements = driver.find_elements(By.TAG_NAME,'p')\n",
    "        if len(no_more_elements) == 1: # or 'css-1h2y9ni' in no_more_elements[0].get_attribute('class'):\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        break\n",
    "\n",
    "\n",
    "# Now you can proceed to extract the content you need\n",
    "try:\n",
    "    get_page_data(driver, data_dict)\n",
    "except StaleElementReferenceException:\n",
    "    print(\"StaleElementReferenceException occurred. Waiting for the page to load again...\")\n",
    "    WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CLASS_NAME, 'css-d5z3ro')))\n",
    "    get_page_data(driver, data_dict)\n",
    "    \n",
    "\n",
    "# Create the DataFrame from the collected data\n",
    "df = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "caeb0b68-6f4c-4639-aca7-240dfa79de32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Names</th>\n",
       "      <th>Product_URLs</th>\n",
       "      <th>Current_Price</th>\n",
       "      <th>Original_Price</th>\n",
       "      <th>Discount_Percentage</th>\n",
       "      <th>Units_Sold</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Featured</th>\n",
       "      <th>Best_Seller</th>\n",
       "      <th>Product_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Himalaya Total Care Baby Pants Diapers</td>\n",
       "      <td>https://www.nykaa.com/himalaya-total-care-baby...</td>\n",
       "      <td>1020</td>\n",
       "      <td>1275</td>\n",
       "      <td>20%</td>\n",
       "      <td>N/A</td>\n",
       "      <td>( 321 )</td>\n",
       "      <td>FEATURED</td>\n",
       "      <td>BESTSELLER</td>\n",
       "      <td>779466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pampers New Baby Diapers - 24 Pack</td>\n",
       "      <td>https://www.nykaa.com/pampers-new-baby-diapers...</td>\n",
       "      <td>360</td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>( 53 )</td>\n",
       "      <td>FEATURED</td>\n",
       "      <td>BESTSELLER</td>\n",
       "      <td>9961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Huggies Wonder Pants Extra Small Size Diaper P...</td>\n",
       "      <td>https://www.nykaa.com/huggies-wonder-pants-ext...</td>\n",
       "      <td>212</td>\n",
       "      <td>249</td>\n",
       "      <td>15%</td>\n",
       "      <td>N/A</td>\n",
       "      <td>( 49 )</td>\n",
       "      <td>N/A</td>\n",
       "      <td>BESTSELLER</td>\n",
       "      <td>5886453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pampers New Diapers Pants, Small</td>\n",
       "      <td>https://www.nykaa.com/pampers-new-diapers-pant...</td>\n",
       "      <td>849</td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>( 58 )</td>\n",
       "      <td>N/A</td>\n",
       "      <td>BESTSELLER</td>\n",
       "      <td>878128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pampers New Diapers Pants, XL</td>\n",
       "      <td>https://www.nykaa.com/pampers-new-diapers-pant...</td>\n",
       "      <td>1199</td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>( 17 )</td>\n",
       "      <td>N/A</td>\n",
       "      <td>BESTSELLER</td>\n",
       "      <td>878131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>MamyPoko Pants Extra Absorb Diapers (XL) - 84 ...</td>\n",
       "      <td>https://www.nykaa.com/mamypoko-pants-extra-abs...</td>\n",
       "      <td>1998</td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>7327716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Huggies Wonder Pants Medium Size Diapers</td>\n",
       "      <td>https://www.nykaa.com/huggies-wonder-pants-med...</td>\n",
       "      <td>499</td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>5886449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Mamypoko Pants Extra Absorb Diapers (Extra Lar...</td>\n",
       "      <td>https://www.nykaa.com/mamypoko-pants-extra-abs...</td>\n",
       "      <td>1499</td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>5771380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>MamyPoko Pants Extra Absorb Diapers (Medium) -...</td>\n",
       "      <td>https://www.nykaa.com/mamypoko-pants-extra-abs...</td>\n",
       "      <td>1998</td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>7327714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Heyday Natural &amp; Organic Baby Diapers Extra La...</td>\n",
       "      <td>https://www.nykaa.com/heyday-natural-organic-b...</td>\n",
       "      <td>379</td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>( 1 )</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>881633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Product_Names  \\\n",
       "0               Himalaya Total Care Baby Pants Diapers   \n",
       "1                   Pampers New Baby Diapers - 24 Pack   \n",
       "2    Huggies Wonder Pants Extra Small Size Diaper P...   \n",
       "3                     Pampers New Diapers Pants, Small   \n",
       "4                        Pampers New Diapers Pants, XL   \n",
       "..                                                 ...   \n",
       "112  MamyPoko Pants Extra Absorb Diapers (XL) - 84 ...   \n",
       "113           Huggies Wonder Pants Medium Size Diapers   \n",
       "114  Mamypoko Pants Extra Absorb Diapers (Extra Lar...   \n",
       "115  MamyPoko Pants Extra Absorb Diapers (Medium) -...   \n",
       "116  Heyday Natural & Organic Baby Diapers Extra La...   \n",
       "\n",
       "                                          Product_URLs Current_Price  \\\n",
       "0    https://www.nykaa.com/himalaya-total-care-baby...          1020   \n",
       "1    https://www.nykaa.com/pampers-new-baby-diapers...           360   \n",
       "2    https://www.nykaa.com/huggies-wonder-pants-ext...           212   \n",
       "3    https://www.nykaa.com/pampers-new-diapers-pant...           849   \n",
       "4    https://www.nykaa.com/pampers-new-diapers-pant...          1199   \n",
       "..                                                 ...           ...   \n",
       "112  https://www.nykaa.com/mamypoko-pants-extra-abs...          1998   \n",
       "113  https://www.nykaa.com/huggies-wonder-pants-med...           499   \n",
       "114  https://www.nykaa.com/mamypoko-pants-extra-abs...          1499   \n",
       "115  https://www.nykaa.com/mamypoko-pants-extra-abs...          1998   \n",
       "116  https://www.nykaa.com/heyday-natural-organic-b...           379   \n",
       "\n",
       "    Original_Price Discount_Percentage Units_Sold  Reviews  Featured  \\\n",
       "0             1275                 20%        N/A  ( 321 )  FEATURED   \n",
       "1                                  N/A        N/A   ( 53 )  FEATURED   \n",
       "2              249                 15%        N/A   ( 49 )       N/A   \n",
       "3                                  N/A        N/A   ( 58 )       N/A   \n",
       "4                                  N/A        N/A   ( 17 )       N/A   \n",
       "..             ...                 ...        ...      ...       ...   \n",
       "112                                N/A        N/A      N/A       N/A   \n",
       "113                                N/A        N/A      N/A       N/A   \n",
       "114                                N/A        N/A      N/A       N/A   \n",
       "115                                N/A        N/A      N/A       N/A   \n",
       "116                                N/A        N/A    ( 1 )       N/A   \n",
       "\n",
       "    Best_Seller Product_ID  \n",
       "0    BESTSELLER     779466  \n",
       "1    BESTSELLER       9961  \n",
       "2    BESTSELLER    5886453  \n",
       "3    BESTSELLER     878128  \n",
       "4    BESTSELLER     878131  \n",
       "..          ...        ...  \n",
       "112         N/A    7327716  \n",
       "113         N/A    5886449  \n",
       "114         N/A    5771380  \n",
       "115         N/A    7327714  \n",
       "116         N/A     881633  \n",
       "\n",
       "[117 rows x 10 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[2]:\n",
    "# Now let use manipulate our data\n",
    "# Let us start by creating a function to extract product ID from the URL\n",
    "def extract_product_id(product_url):\n",
    "    match = re.search(r'productId=(\\d+)', product_url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "# Apply the function to create the 'Product_ID' column\n",
    "df['Product_ID'] = df['Product_URLs'].apply(extract_product_id)\n",
    "\n",
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "59c81f1f-9254-4c44-92a5-094a70fe1741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Ended Successfully :)\n"
     ]
    }
   ],
   "source": [
    "# In[3]:\n",
    "#Lets convert the file into excel\n",
    "current_datetime = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "filename = f\"nykaa_scrape_{current_datetime}.xlsx\"\n",
    "df.to_excel(filename,index=False)\n",
    "\n",
    "print(\"Process Ended Successfully :)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
